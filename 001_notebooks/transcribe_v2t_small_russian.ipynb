{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPvv5k1JXMhkRaJVg9iDI/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alecseiterr/Tetrabot/blob/main/Andrey_Novikov/002_notebooks/transcribe_v2t_small_russian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка распознавания голосовых команд записанных в файлы и произносимых с микрофона с помощью библиотеки vosk (компактная модель: vosk-model-small-ru-0.22 со страницы https://alphacephei.com/vosk/models"
      ],
      "metadata": {
        "id": "g9Vw-tFEpYBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Первая часть. Проверка распознавания голосовых команд из wav-файлов"
      ],
      "metadata": {
        "id": "5doJUFdpqDwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установим библиотеки vosk и pydub\n",
        "!pip install vosk pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdXmM7zlb81w",
        "outputId": "04aecd28-a079-4ee8-f81c-77eebe4b9d53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.15.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.1)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting websockets (from vosk)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2023.7.22)\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22429 sha256=26170ca3cadd66a89e6c188ed909c2eb68776c33a24b39e9848b539e4815669c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built srt\n",
            "Installing collected packages: pydub, websockets, srt, vosk\n",
            "Successfully installed pydub-0.25.1 srt-3.5.3 vosk-0.3.45 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JOuytpfubecy"
      },
      "outputs": [],
      "source": [
        "# Загрузим необходимые модули и библиотеки\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from google.colab import drive\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Примонтируем Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJjb0zrpcJak",
        "outputId": "273b6b7d-0beb-42ca-e5de-45803accd966"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Скачаем малую модель vosk-model-small-ru-0.22 со страницы https://alphacephei.com/vosk/models\n",
        "*   Загрузим малую модель в папку /content/drive/MyDrive/AI_data/tetrabot/models\n",
        "*   Распакуем малую модель с помощью кода, приведенного ниже в папку /content/model"
      ],
      "metadata": {
        "id": "ymcwHC-YkR7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file = '/content/drive/MyDrive/AI_data/tetrabot/models/vosk-model-small-ru-0.22.zip'\n",
        "#zip_file = '/content/drive/MyDrive/AI_data/tetrabot/models/vosk-model-ru-0.42.zip'\n",
        "extract_dir = '/content/model'\n",
        "shutil.unpack_archive(zip_file, extract_dir)"
      ],
      "metadata": {
        "id": "vIqNbTKOkw07"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Укажем путь к модели\n",
        "vosk_model_path = \"/content/model/vosk-model-small-ru-0.22\"\n",
        "#vosk_model_path = '/content/model/vosk-model-ru-0.42'\n",
        "\n",
        "# Загрузим модель\n",
        "vosk_model = Model(vosk_model_path)\n",
        "\n",
        "# Создадим экземпляр распознавателя голоса с помощью модели Vosk\n",
        "recognizer = KaldiRecognizer(vosk_model, 16000)"
      ],
      "metadata": {
        "id": "b7GNCyZpbo7R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция распознавания голосовых команд из записанных файлов\n",
        "def recognize_voice_command(audio_file_path):\n",
        "    # Загрузка аудио файлов в виде AudioSegment\n",
        "    audio = AudioSegment.from_wav(audio_file_path)\n",
        "\n",
        "    # Преобразование записи в один канал с частотой дискретизации 16 kHz (требование модели Vosk)\n",
        "    audio = audio.set_frame_rate(16000).set_channels(1)\n",
        "\n",
        "    # Разпознавание голоса\n",
        "    results = []\n",
        "    chunk_size_ms = 4000  # Обработка потока чанками в 4 секунды\n",
        "    for i in range(0, len(audio), chunk_size_ms):\n",
        "        chunk = audio[i:i + chunk_size_ms]\n",
        "        if len(chunk) > 0:\n",
        "            raw_data = chunk.raw_data\n",
        "            recognizer.AcceptWaveform(raw_data)\n",
        "            result = json.loads(recognizer.Result())\n",
        "            results.append(result)\n",
        "\n",
        "    # Сборка распознанных фрагментов и вывод на экран\n",
        "    recognized_text = \" \".join(result['text'] for result in results)\n",
        "    print(\"Распознанный текст: {:25}\".format(recognized_text))\n"
      ],
      "metadata": {
        "id": "Lf6MZQfunhSJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Воспользуемся записями своего голоса (Вариант 1)\n",
        "audio_folder_path = \"/content/drive/MyDrive/AI_data/tetrabot/my_voice\"\n",
        "\n",
        "# Воспользуемся записями своего голосаn (Вариант 2)\n",
        "#audio_folder_path = \"/content/drive/MyDrive/AI_data/tetrabot/my_voice_Troy\"\n",
        "\n",
        "# Запись, предоставленная заказчиком\n",
        "#audio_folder_path = \"/content/drive/MyDrive/AI_data/tetrabot/tetrabot_new/golos_shagohod/golos_blizko\""
      ],
      "metadata": {
        "id": "0_qCbiLsHM02"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим распознавание и транскрибирование всех файлов в заданной папке\n",
        "for filename in os.listdir(audio_folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file_path = os.path.join(audio_folder_path, filename)\n",
        "        print(\"Процессинг файла  : {:25}\".format(filename))\n",
        "        recognize_voice_command(audio_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mxr0qrGdbqm",
        "outputId": "3780b3fb-2518-4266-ed32-d6771f8feeb5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Процессинг файла  : направо.wav              \n",
            "Распознанный текст: направо                  \n",
            "Процессинг файла  : вправо.wav               \n",
            "Распознанный текст: вправо                   \n",
            "Процессинг файла  : экспелиармус.wav         \n",
            "Распознанный текст: экс пили арбуз           \n",
            "Процессинг файла  : вингардиум_левиоса.wav   \n",
            "Распознанный текст: вин гарди ум леви о с а  \n",
            "Процессинг файла  : алохомора.wav            \n",
            "Распознанный текст: олафа мора               \n",
            "Процессинг файла  : поворачивай_вправо.wav  \n",
            "Распознанный текст: поворачивает вправо      \n",
            "Процессинг файла  : экспекто_патронум.wav    \n",
            "Распознанный текст: эксперт кто патроном     \n",
            "Процессинг файла  : авада_кедавра.wav        \n",
            "Распознанный текст: а вода ке дабро          \n",
            "Процессинг файла  : петрификус_тоталус.wav   \n",
            "Распознанный текст: петри фикус тотал ос     \n",
            "Процессинг файла  : остановись.wav           \n",
            "Распознанный текст: остановись               \n",
            "Процессинг файла  : включи_автоматический_режим.wav\n",
            "Распознанный текст: включи автоматический режим \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вторая часть. Проверка распознавания голосовых команд записанных через микрофон"
      ],
      "metadata": {
        "id": "7-1U-uX-bxs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка дополнительных библиотек\n",
        "!apt-get update\n",
        "!apt-get install portaudio19-dev\n",
        "!pip install vosk pydub pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_RTxb7Zb8eX",
        "outputId": "4f4e6ab0-7042-4c20-d5b9-aa91e186455b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [969 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,070 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,238 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,257 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,090 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,197 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,127 kB]\n",
            "Fetched 9,309 kB in 4s (2,388 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 1s (293 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: vosk in /usr/local/lib/python3.10/dist-packages (0.3.45)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.13.tar.gz (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.15.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.1)\n",
            "Requirement already satisfied: srt in /usr/local/lib/python3.10/dist-packages (from vosk) (3.5.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from vosk) (11.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2023.7.22)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=PyAudio-0.2.13-cp310-cp310-linux_x86_64.whl size=63867 sha256=605e7759181122920df35745062e3e75688c553e04224a646607065455681528\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/f1/c2/d102b4765a82c5a7bb273998dca7e4a53fc58e9a1a516fda81\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg -s libasound2-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql7RE3ZFE9tJ",
        "outputId": "54e3b3b6-fe1a-4f33-dcf8-ea7c465433a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package: libasound2-dev\n",
            "Status: install ok installed\n",
            "Priority: optional\n",
            "Section: libdevel\n",
            "Installed-Size: 677\n",
            "Maintainer: Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>\n",
            "Architecture: amd64\n",
            "Multi-Arch: same\n",
            "Source: alsa-lib\n",
            "Version: 1.2.6.1-1ubuntu1\n",
            "Provides: libasound-dev\n",
            "Depends: libasound2 (= 1.2.6.1-1ubuntu1)\n",
            "Suggests: libasound2-doc\n",
            "Description: shared library for ALSA applications -- development files\n",
            " This package contains files required for developing software\n",
            " that makes use of libasound2, the ALSA library.\n",
            " .\n",
            " ALSA is the Advanced Linux Sound Architecture.\n",
            "Homepage: https://www.alsa-project.org/\n",
            "Original-Maintainer: Debian ALSA Maintainers <pkg-alsa-devel@lists.alioth.debian.org>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK2NmPcaKexW",
        "outputId": "acca1a9f-bd62-403c-c072-adce9df178ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка дополнительных библиотек\n",
        "#import os\n",
        "#import sys\n",
        "#import json\n",
        "import pyaudio\n",
        "import wave\n",
        "#from vosk import Model, KaldiRecognizer\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg"
      ],
      "metadata": {
        "id": "Qxgq6rRgdDiY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Java-скрипт необходимый для записи голоса с микрофона"
      ],
      "metadata": {
        "id": "ZXs-du-Xu2Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>                                                      // создаем тег <script>, сообщающий браузеру о том, что внутри находится исполняемый код JavaScript\n",
        "var my_div = document.createElement(\"DIV\");                   // создаем новый элемент DIV(тег-контейнер для логического выделения блока документа)\n",
        "var my_p = document.createElement(\"P\");                       // создаем новый элемент P(параграф для логической группировки текста)\n",
        "var my_btn = document.createElement(\"BUTTON\");                // создаем новый элемент(кнопку) BUTTON\n",
        "var t = document.createTextNode(\"Нажмите старт для записи\");  // создаем текстовое содержимое для кнопки\n",
        "\n",
        "my_btn.appendChild(t);                                        // добавляем текстовое содержимое элементу BUTTON\n",
        "my_div.appendChild(my_btn);                                   // кнопку с текстом BUTTON добавляем в блок DIV\n",
        "document.body.appendChild(my_div);                            // добавляем наш блок в элемент <body>(\"тело\", для хранения содержимого веб-страницы)\n",
        "\n",
        "var base64data = 0;                                           // будем использовать для аудиоданных метод кодирования информации в 64-разрядный код\n",
        "var reader;                                                   // создаем переменную для чтения файла\n",
        "var recorder, gumStream;                                      // объявляем переменные для записи данных/потока\n",
        "var recordButton = my_btn;                                    // создаем переменную для кнопки записи аудио с микрофона\n",
        "\n",
        "var handleSuccess = function(stream) {                        // объявляем функцию для работы с потоками данных\n",
        "  gumStream = stream;                                         // создаем переменную для потока\n",
        "  var options = {\n",
        "    mimeType : 'audio/webm;codecs=opus'                       // в опциях задаем медиа тип с аудиоформатом и кодеками\n",
        "  };\n",
        "  recorder = new MediaRecorder(stream);                       // создаем новый объект MediaRecorder, получающий медиапоток для записи.\n",
        "                                                              // MediaRecorder - интерфейс MediaStream Recording API представляющий функциональность для простой записи медиа. Создается..\n",
        "                                                              // ..с использованием MediaRecorder() конструктора.\n",
        "  recorder.ondataavailable = function(e) {                    // вызываем обработчик dataavailable события, запускаемое по окончанию записи\n",
        "    var url = URL.createObjectURL(e.data);                    // этим методом создаем DOMString(UTF-16 String), содержащий URL с указанием на объект e.data\n",
        "    var preview = document.createElement('audio');            // создаем элемент-тег аудио\n",
        "    preview.controls = true;                                  // активизируем элементы управления\n",
        "    preview.src = url;                                        // берем в кач-ве исходных данных файл, содержащийся в записанной ранее URL\n",
        "    document.body.appendChild(preview);                       // добавляем элемент аудио в <body>(\"тело\", для хранения содержимого веб-страницы)\n",
        "\n",
        "    reader = new FileReader();                                // создаем объект класса FileReader для чтения разных источников данных\n",
        "    reader.readAsDataURL(e.data);                             // читаем содержимое указанного файла\n",
        "    reader.onloadend = function() {                           // обработчик события, запускаемого после передачи данных\n",
        "      base64data = reader.result;                             // записываем прочитанное содержимое в base64data\n",
        "    }\n",
        "  };\n",
        "  recorder.start();  // начало записи медиа\n",
        "  };\n",
        "\n",
        "// такой текст будет на кнопке BUTTON во время записи аудио\n",
        "recordButton.innerText = \"Идёт запись... нажмите для остановки\";\n",
        "\n",
        "// запрос разрешения пользователя на доступ к устройству захвата аудио(микрофон), указываем True\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {                                  // функция опишет действия по завершению записи (после клика мышкой по кнопке \"Recording... press to stop\")\n",
        "  if (recorder && recorder.state == \"recording\") {            // если рекордер находится в процессе записи\n",
        "      recorder.stop();  // рекордер прерывается\n",
        "      gumStream.getAudioTracks()[0].stop();                   // отключается запись и доступ к микрофону\n",
        "      recordButton.innerText = \"\"    // эта надпись(сохранение записи) отобразится на кнопке BUTTON\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {                                          // создаем функцию с задержкой вызова\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "\n",
        "  // new Promise - конструкция для отложенных вычислений\n",
        "  // setTimeout позволяет вызвать функцию один раз через определённый интервал времени\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.onclick = ()=>{      // при нажатии левой кнопкой мыши на кнопку \"Recording... press to stop\"\n",
        "toggleRecording()                 // вызывается функция завершения аудиозаписи\n",
        "\n",
        "sleep(2000).then(() => {          // и после задержки 2000мс(2 сек)\n",
        "  resolve(base64data.toString())  // полученные данные из формата base64 преобразовываем в строку\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "79AJr_t7QYYk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Функция записи звука через микрофон (в виде numpy-массива)"
      ],
      "metadata": {
        "id": "3IJatCnsvNJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ],
      "metadata": {
        "id": "048HpX1bLQvg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Проверка работоспособности записи через микрофон"
      ],
      "metadata": {
        "id": "YUfC2OU_vgG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sr = get_audio()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "Uq-9P1B3LXIW",
        "outputId": "1f667f7f-bed6-42e7-b073-e00517dd9d30"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>                                                      // создаем тег <script>, сообщающий браузеру о том, что внутри находится исполняемый код JavaScript\n",
              "var my_div = document.createElement(\"DIV\");                   // создаем новый элемент DIV(тег-контейнер для логического выделения блока документа)\n",
              "var my_p = document.createElement(\"P\");                       // создаем новый элемент P(параграф для логической группировки текста)\n",
              "var my_btn = document.createElement(\"BUTTON\");                // создаем новый элемент(кнопку) BUTTON\n",
              "var t = document.createTextNode(\"Нажмите старт для записи\");  // создаем текстовое содержимое для кнопки\n",
              "\n",
              "my_btn.appendChild(t);                                        // добавляем текстовое содержимое элементу BUTTON\n",
              "my_div.appendChild(my_btn);                                   // кнопку с текстом BUTTON добавляем в блок DIV\n",
              "document.body.appendChild(my_div);                            // добавляем наш блок в элемент <body>(\"тело\", для хранения содержимого веб-страницы)\n",
              "\n",
              "var base64data = 0;                                           // будем использовать для аудиоданных метод кодирования информации в 64-разрядный код\n",
              "var reader;                                                   // создаем переменную для чтения файла\n",
              "var recorder, gumStream;                                      // объявляем переменные для записи данных/потока\n",
              "var recordButton = my_btn;                                    // создаем переменную для кнопки записи аудио с микрофона\n",
              "\n",
              "var handleSuccess = function(stream) {                        // объявляем функцию для работы с потоками данных\n",
              "  gumStream = stream;                                         // создаем переменную для потока\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus'                       // в опциях задаем медиа тип с аудиоформатом и кодеками\n",
              "  };            \n",
              "  recorder = new MediaRecorder(stream);                       // создаем новый объект MediaRecorder, получающий медиапоток для записи.\n",
              "                                                              // MediaRecorder - интерфейс MediaStream Recording API представляющий функциональность для простой записи медиа. Создается..\n",
              "                                                              // ..с использованием MediaRecorder() конструктора.\n",
              "  recorder.ondataavailable = function(e) {                    // вызываем обработчик dataavailable события, запускаемое по окончанию записи          \n",
              "    var url = URL.createObjectURL(e.data);                    // этим методом создаем DOMString(UTF-16 String), содержащий URL с указанием на объект e.data\n",
              "    var preview = document.createElement('audio');            // создаем элемент-тег аудио\n",
              "    preview.controls = true;                                  // активизируем элементы управления\n",
              "    preview.src = url;                                        // берем в кач-ве исходных данных файл, содержащийся в записанной ранее URL\n",
              "    document.body.appendChild(preview);                       // добавляем элемент аудио в <body>(\"тело\", для хранения содержимого веб-страницы)\n",
              "\n",
              "    reader = new FileReader();                                // создаем объект класса FileReader для чтения разных источников данных\n",
              "    reader.readAsDataURL(e.data);                             // читаем содержимое указанного файла\n",
              "    reader.onloadend = function() {                           // обработчик события, запускаемого после передачи данных\n",
              "      base64data = reader.result;                             // записываем прочитанное содержимое в base64data\n",
              "    }\n",
              "  };\n",
              "  recorder.start();  // начало записи медиа\n",
              "  };\n",
              "\n",
              "// такой текст будет на кнопке BUTTON во время записи аудио\n",
              "recordButton.innerText = \"Идёт запись... нажмите для остановки\"; \n",
              "\n",
              "// запрос разрешения пользователя на доступ к устройству захвата аудио(микрофон), указываем True\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {                                  // функция опишет действия по завершению записи (после клика мышкой по кнопке \"Recording... press to stop\")\n",
              "  if (recorder && recorder.state == \"recording\") {            // если рекордер находится в процессе записи \n",
              "      recorder.stop();  // рекордер прерывается\n",
              "      gumStream.getAudioTracks()[0].stop();                   // отключается запись и доступ к микрофону\n",
              "      recordButton.innerText = \"\"    // эта надпись(сохранение записи) отобразится на кнопке BUTTON \n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {                                          // создаем функцию с задержкой вызова\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));  \n",
              "\n",
              "  // new Promise - конструкция для отложенных вычислений\n",
              "  // setTimeout позволяет вызвать функцию один раз через определённый интервал времени\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{      // при нажатии левой кнопкой мыши на кнопку \"Recording... press to stop\"\n",
              "toggleRecording()                 // вызывается функция завершения аудиозаписи\n",
              "\n",
              "sleep(2000).then(() => {          // и после задержки 2000мс(2 сек)\n",
              "  resolve(base64data.toString())  // полученные данные из формата base64 преобразовываем в строку\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Функция, объединяющая запись через микрофон и распознавание голоса"
      ],
      "metadata": {
        "id": "hChS6TrXvtb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция распознавания голосовых команд через микрофон\n",
        "def recognize_voice_command_mic():\n",
        "    # Загрузка аудио через микрофон\n",
        "    audio, sr = get_audio()\n",
        "    # Преобразование numpy-массива в объект AudioSegment\n",
        "    audio_segment = AudioSegment(\n",
        "                                audio.tobytes(),\n",
        "                                frame_rate=sr,\n",
        "                                sample_width=audio.dtype.itemsize,\n",
        "                                channels=1\n",
        "                                )\n",
        "    # Преобразование записи в один канал с частотой дискретизации 16 kHz (требование модели Vosk)\n",
        "    audio = audio_segment.set_frame_rate(16000).set_channels(1)\n",
        "\n",
        "    # Распознавание голоса\n",
        "    results = []\n",
        "    chunk_size_ms = 4000  # Обработка потока чанками в 4 секунды\n",
        "    for i in range(0, len(audio), chunk_size_ms):\n",
        "        chunk = audio[i:i + chunk_size_ms]\n",
        "        if len(chunk) > 0:\n",
        "            raw_data = chunk.raw_data\n",
        "            recognizer.AcceptWaveform(raw_data)\n",
        "            result = json.loads(recognizer.Result())\n",
        "            results.append(result)\n",
        "\n",
        "    # Сборка распознанных фрагментов и вывод на экран\n",
        "    recognized_text = \" \".join(result['text'] for result in results)\n",
        "    print(f\"Распознанный текст: {recognized_text}\")\n"
      ],
      "metadata": {
        "id": "MX-v2G-ciwZb"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recognize_voice_command_mic()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "tMz3eGHQjS-_",
        "outputId": "d1a9baf7-be30-48af-e06e-f38716f3c3f8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>                                                      // создаем тег <script>, сообщающий браузеру о том, что внутри находится исполняемый код JavaScript\n",
              "var my_div = document.createElement(\"DIV\");                   // создаем новый элемент DIV(тег-контейнер для логического выделения блока документа)\n",
              "var my_p = document.createElement(\"P\");                       // создаем новый элемент P(параграф для логической группировки текста)\n",
              "var my_btn = document.createElement(\"BUTTON\");                // создаем новый элемент(кнопку) BUTTON\n",
              "var t = document.createTextNode(\"Нажмите старт для записи\");  // создаем текстовое содержимое для кнопки\n",
              "\n",
              "my_btn.appendChild(t);                                        // добавляем текстовое содержимое элементу BUTTON\n",
              "my_div.appendChild(my_btn);                                   // кнопку с текстом BUTTON добавляем в блок DIV\n",
              "document.body.appendChild(my_div);                            // добавляем наш блок в элемент <body>(\"тело\", для хранения содержимого веб-страницы)\n",
              "\n",
              "var base64data = 0;                                           // будем использовать для аудиоданных метод кодирования информации в 64-разрядный код\n",
              "var reader;                                                   // создаем переменную для чтения файла\n",
              "var recorder, gumStream;                                      // объявляем переменные для записи данных/потока\n",
              "var recordButton = my_btn;                                    // создаем переменную для кнопки записи аудио с микрофона\n",
              "\n",
              "var handleSuccess = function(stream) {                        // объявляем функцию для работы с потоками данных\n",
              "  gumStream = stream;                                         // создаем переменную для потока\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus'                       // в опциях задаем медиа тип с аудиоформатом и кодеками\n",
              "  };            \n",
              "  recorder = new MediaRecorder(stream);                       // создаем новый объект MediaRecorder, получающий медиапоток для записи.\n",
              "                                                              // MediaRecorder - интерфейс MediaStream Recording API представляющий функциональность для простой записи медиа. Создается..\n",
              "                                                              // ..с использованием MediaRecorder() конструктора.\n",
              "  recorder.ondataavailable = function(e) {                    // вызываем обработчик dataavailable события, запускаемое по окончанию записи          \n",
              "    var url = URL.createObjectURL(e.data);                    // этим методом создаем DOMString(UTF-16 String), содержащий URL с указанием на объект e.data\n",
              "    var preview = document.createElement('audio');            // создаем элемент-тег аудио\n",
              "    preview.controls = true;                                  // активизируем элементы управления\n",
              "    preview.src = url;                                        // берем в кач-ве исходных данных файл, содержащийся в записанной ранее URL\n",
              "    document.body.appendChild(preview);                       // добавляем элемент аудио в <body>(\"тело\", для хранения содержимого веб-страницы)\n",
              "\n",
              "    reader = new FileReader();                                // создаем объект класса FileReader для чтения разных источников данных\n",
              "    reader.readAsDataURL(e.data);                             // читаем содержимое указанного файла\n",
              "    reader.onloadend = function() {                           // обработчик события, запускаемого после передачи данных\n",
              "      base64data = reader.result;                             // записываем прочитанное содержимое в base64data\n",
              "    }\n",
              "  };\n",
              "  recorder.start();  // начало записи медиа\n",
              "  };\n",
              "\n",
              "// такой текст будет на кнопке BUTTON во время записи аудио\n",
              "recordButton.innerText = \"Идёт запись... нажмите для остановки\"; \n",
              "\n",
              "// запрос разрешения пользователя на доступ к устройству захвата аудио(микрофон), указываем True\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {                                  // функция опишет действия по завершению записи (после клика мышкой по кнопке \"Recording... press to stop\")\n",
              "  if (recorder && recorder.state == \"recording\") {            // если рекордер находится в процессе записи \n",
              "      recorder.stop();  // рекордер прерывается\n",
              "      gumStream.getAudioTracks()[0].stop();                   // отключается запись и доступ к микрофону\n",
              "      recordButton.innerText = \"\"    // эта надпись(сохранение записи) отобразится на кнопке BUTTON \n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {                                          // создаем функцию с задержкой вызова\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));  \n",
              "\n",
              "  // new Promise - конструкция для отложенных вычислений\n",
              "  // setTimeout позволяет вызвать функцию один раз через определённый интервал времени\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{      // при нажатии левой кнопкой мыши на кнопку \"Recording... press to stop\"\n",
              "toggleRecording()                 // вызывается функция завершения аудиозаписи\n",
              "\n",
              "sleep(2000).then(() => {          // и после задержки 2000мс(2 сек)\n",
              "  resolve(base64data.toString())  // полученные данные из формата base64 преобразовываем в строку\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Распознанный текст: на сегодня все задачи выполнены иду гулять с собакой\n"
          ]
        }
      ]
    }
  ]
}